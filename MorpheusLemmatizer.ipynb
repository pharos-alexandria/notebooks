{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize file with Perseids Morpheus Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Perseids Morpheus and query Lemmata and Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests # query website\n",
    "import json\n",
    "from nltk.tokenize import RegexpTokenizer # tokenize\n",
    "def queryMorpheusLem(word):\n",
    "    \"\"\"Works only online. Query Perseids Morpeus for Lemma (code inspired by ideas from CLTK's lemma.py).\"\"\"\n",
    "    suche = {\"word\": word}\n",
    "    try:\n",
    "        r = requests.get('http://morph.perseids.org/analysis/word?lang=grc&engine=morpheusgrc', data=suche, timeout=10)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Timeout. Please try again.\")\n",
    "    else:\n",
    "        data = r.json()\n",
    "        result = {} # output results as dictionary\n",
    "        result[\"Word\"] = word\n",
    "        try:\n",
    "            entry = data[\"RDF\"][\"Annotation\"][\"Body\"]\n",
    "        except KeyError:\n",
    "            result[\"Lemma\"] = word # Copy word as lemma \n",
    "            result[\"Morphology\"] = \"NOT FOUND\"\n",
    "            result[\"Error\"] = \"NOT FOUND\"  # error indicator\n",
    "        else:\n",
    "            # Test if there are more entries\n",
    "            # TODO: Better way to deal with words with more lemma entries: how to find the correct lemma?\n",
    "            try: \n",
    "                entry[1][\"rest\"]\n",
    "                list_hdwd = []\n",
    "                list_pos = []\n",
    "                for i in range(len(entry)):\n",
    "                    headword = entry[i][\"rest\"][\"entry\"][\"dict\"][\"hdwd\"][\"$\"]\n",
    "                    infl = entry[i][\"rest\"][\"entry\"][\"infl\"]\n",
    "                    if isinstance(infl, list):\n",
    "                        list_pos1 = []\n",
    "                        for inst in range(len(infl)):\n",
    "                            POS = infl[inst][\"pofs\"][\"$\"]\n",
    "                            if POS == \"verb\":\n",
    "                                MOOD = infl[inst][\"mood\"][\"$\"]\n",
    "                                TENSE = infl[inst][\"tense\"][\"$\"]\n",
    "                                VOICE = infl[inst][\"voice\"][\"$\"]\n",
    "                                try:\n",
    "                                    NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                    PERS = infl[inst][\"pers\"][\"$\"]\n",
    "                                    posentry = POS+\"-\"+MOOD+\"-\"+NUM+\"-\"+PERS+\"-\"+TENSE+\"-\"+VOICE\n",
    "                                except KeyError:\n",
    "                                    posentry = POS+\"-\"+MOOD+\"-\"+TENSE+\"-\"+VOICE\n",
    "                            elif POS == \"verb participle\":\n",
    "                                CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                                NUM = infl[inst][\"num\"][\"$\"]                                \n",
    "                                TENSE = infl[inst][\"tense\"][\"$\"]\n",
    "                                VOICE = infl[inst][\"voice\"][\"$\"]  \n",
    "                                posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM+\"-\"+TENSE+\"-\"+VOICE\n",
    "                            elif POS == \"pronoun\":\n",
    "                                CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+CASE+\"-\"+NUM\n",
    "                            elif POS == \"noun\":\n",
    "                                try:\n",
    "                                    CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                    GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                                    NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                    posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                                except KeyError:\n",
    "                                    TYPE = infl[inst][\"stemtype\"][\"$\"]\n",
    "                                    posentry = POS+\"-\"+TYPE\n",
    "                            elif POS == \"article\":\n",
    "                                CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                                NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                            elif POS == \"adjective\":\n",
    "                                try:\n",
    "                                    GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                                    if GEND == \"adverbial\":\n",
    "                                        posentry = POS+\"-\"+GEND\n",
    "                                    else:\n",
    "                                        CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                        NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                        try:\n",
    "                                            COMP = infl[inst][\"comp\"][\"$\"]\n",
    "                                            posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+COMP+\"-\"+NUM\n",
    "                                        except KeyError:\n",
    "                                            posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                                except KeyError:\n",
    "                                    CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                    NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                    try:\n",
    "                                        COMP = infl[inst][\"comp\"][\"$\"]\n",
    "                                        posentry = POS+\"-\"+CASE+\"-\"+COMP+\"-\"+NUM\n",
    "                                    except KeyError:\n",
    "                                        posentry = POS+\"-\"+CASE+\"-\"+NUM\n",
    "                            else:\n",
    "                                posentry = POS\n",
    "                            list_pos1.append(posentry)\n",
    "                        instance = \"/\".join(list_pos1)\n",
    "                        list_pos.append(instance)\n",
    "                    else:\n",
    "                        POS = infl[\"pofs\"][\"$\"]\n",
    "                        if POS == \"verb\":\n",
    "                            MOOD = infl[\"mood\"][\"$\"]\n",
    "                            TENSE = infl[\"tense\"][\"$\"]\n",
    "                            VOICE = infl[\"voice\"][\"$\"]\n",
    "                            try:\n",
    "                                NUM = infl[\"num\"][\"$\"]\n",
    "                                PERS = infl[\"pers\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+MOOD+\"-\"+NUM+\"-\"+PERS+\"-\"+TENSE+\"-\"+VOICE\n",
    "                            except KeyError:\n",
    "                                posentry = POS+\"-\"+MOOD+\"-\"+TENSE+\"-\"+VOICE\n",
    "                        elif POS == \"verb participle\":\n",
    "                            CASE = infl[\"case\"][\"$\"]\n",
    "                            GEND = infl[\"gend\"][\"$\"]\n",
    "                            NUM = infl[\"num\"][\"$\"]                                \n",
    "                            TENSE = infl[\"tense\"][\"$\"]\n",
    "                            VOICE = infl[\"voice\"][\"$\"]  \n",
    "                            posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM+\"-\"+TENSE+\"-\"+VOICE      \n",
    "                        elif POS == \"pronoun\":\n",
    "                            CASE = infl[\"case\"][\"$\"]\n",
    "                            NUM = infl[\"num\"][\"$\"]\n",
    "                            posentry = POS+\"-\"+CASE+\"-\"+NUM\n",
    "                        elif POS == \"noun\":\n",
    "                            try:\n",
    "                                CASE = infl[\"case\"][\"$\"]\n",
    "                                GEND = infl[\"gend\"][\"$\"]\n",
    "                                NUM = infl[\"num\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM    \n",
    "                            except KeyError:\n",
    "                                TYPE = infl[\"stemtype\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+TYPE\n",
    "                        elif POS == \"article\":\n",
    "                            CASE = infl[\"case\"][\"$\"]\n",
    "                            GEND = infl[\"gend\"][\"$\"]\n",
    "                            NUM = infl[\"num\"][\"$\"]\n",
    "                            posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                        elif POS == \"adjective\":\n",
    "                            try:\n",
    "                                GEND = infl[\"gend\"][\"$\"]\n",
    "                                if GEND == \"adverbial\":\n",
    "                                    posentry = POS+\"-\"+GEND\n",
    "                                else:\n",
    "                                    CASE = infl[\"case\"][\"$\"]\n",
    "                                    NUM = infl[\"num\"][\"$\"]\n",
    "                                    try:\n",
    "                                        COMP = infl[\"comp\"][\"$\"]\n",
    "                                        posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+COMP+\"-\"+NUM\n",
    "                                    except KeyError:\n",
    "                                        posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                            except KeyError:\n",
    "                                CASE = infl[\"case\"][\"$\"]\n",
    "                                NUM = infl[\"num\"][\"$\"]\n",
    "                                try:\n",
    "                                    COMP = infl[\"comp\"][\"$\"]\n",
    "                                    posentry = POS+\"-\"+CASE+\"-\"+COMP+\"-\"+NUM\n",
    "                                except KeyError:\n",
    "                                    posentry = POS+\"-\"+CASE+\"-\"+NUM\n",
    "                        else:\n",
    "                            posentry = POS\n",
    "                        list_pos.append(posentry)\n",
    "                    list_hdwd.append(headword)\n",
    "                result[\"Lemma\"] = \"|\".join(list_hdwd)\n",
    "                result[\"Morphology\"] = \"|\".join(list_pos)\n",
    "            except KeyError:\n",
    "                headword = entry[\"rest\"][\"entry\"][\"dict\"][\"hdwd\"][\"$\"]\n",
    "                infl = entry[\"rest\"][\"entry\"][\"infl\"]\n",
    "                if isinstance(infl, list):\n",
    "                    list_pos1 = []\n",
    "                    for inst in range(len(infl)):\n",
    "                        POS = infl[inst][\"pofs\"][\"$\"]\n",
    "                        if POS == \"verb\":\n",
    "                            MOOD = infl[inst][\"mood\"][\"$\"]\n",
    "                            TENSE = infl[inst][\"tense\"][\"$\"]\n",
    "                            VOICE = infl[inst][\"voice\"][\"$\"]\n",
    "                            try:\n",
    "                                NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                PERS = infl[inst][\"pers\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+MOOD+\"-\"+NUM+\"-\"+PERS+\"-\"+TENSE+\"-\"+VOICE\n",
    "                            except KeyError:\n",
    "                                posentry = POS+\"-\"+MOOD+\"-\"+TENSE+\"-\"+VOICE\n",
    "                        elif POS == \"verb participle\":\n",
    "                            CASE = infl[inst][\"case\"][\"$\"]\n",
    "                            GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                            NUM = infl[inst][\"num\"][\"$\"]                                \n",
    "                            TENSE = infl[inst][\"tense\"][\"$\"]\n",
    "                            VOICE = infl[inst][\"voice\"][\"$\"]  \n",
    "                            posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM+\"-\"+TENSE+\"-\"+VOICE\n",
    "                        elif POS == \"pronoun\":\n",
    "                            CASE = infl[inst][\"case\"][\"$\"]\n",
    "                            NUM = infl[inst][\"num\"][\"$\"]\n",
    "                            posentry = POS+\"-\"+CASE+\"-\"+NUM\n",
    "                        elif POS == \"noun\":\n",
    "                            try:\n",
    "                                CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                                NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                            except KeyError:\n",
    "                                TYPE = infl[inst][\"stemtype\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+TYPE\n",
    "                        elif POS == \"article\":\n",
    "                            CASE = infl[inst][\"case\"][\"$\"]\n",
    "                            GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                            NUM = infl[inst][\"num\"][\"$\"]\n",
    "                            posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                        elif POS == \"adjective\":\n",
    "                            try:\n",
    "                                GEND = infl[inst][\"gend\"][\"$\"]\n",
    "                                if GEND == \"adverbial\":\n",
    "                                    posentry = POS+\"-\"+GEND\n",
    "                                else:\n",
    "                                    CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                    NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                    try:\n",
    "                                        COMP = infl[inst][\"comp\"][\"$\"]\n",
    "                                        posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+COMP+\"-\"+NUM\n",
    "                                    except KeyError:\n",
    "                                        posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                            except KeyError:\n",
    "                                CASE = infl[inst][\"case\"][\"$\"]\n",
    "                                NUM = infl[inst][\"num\"][\"$\"]\n",
    "                                try:\n",
    "                                    COMP = infl[inst][\"comp\"][\"$\"]\n",
    "                                    posentry = POS+\"-\"+CASE+\"-\"+COMP+\"-\"+NUM\n",
    "                                except KeyError:\n",
    "                                    posentry = POS+\"-\"+CASE+\"-\"+NUM\n",
    "                        else:\n",
    "                            posentry = POS\n",
    "                        list_pos1.append(posentry)\n",
    "                    posentry = \"/\".join(list_pos1)\n",
    "                else:\n",
    "                    POS = infl[\"pofs\"][\"$\"]\n",
    "                    if POS == \"verb\":\n",
    "                        MOOD = infl[\"mood\"][\"$\"]\n",
    "                        TENSE = infl[\"tense\"][\"$\"]\n",
    "                        VOICE = infl[\"voice\"][\"$\"]\n",
    "                        try:\n",
    "                            NUM = infl[\"num\"][\"$\"]\n",
    "                            PERS = infl[\"pers\"][\"$\"]\n",
    "                            posentry = POS+\"-\"+MOOD+\"-\"+NUM+\"-\"+PERS+\"-\"+TENSE+\"-\"+VOICE\n",
    "                        except KeyError:\n",
    "                            posentry = POS+\"-\"+MOOD+\"-\"+TENSE+\"-\"+VOICE\n",
    "                    elif POS == \"verb participle\":\n",
    "                        CASE = infl[\"case\"][\"$\"]\n",
    "                        GEND = infl[\"gend\"][\"$\"]\n",
    "                        NUM = infl[\"num\"][\"$\"]                                \n",
    "                        TENSE = infl[\"tense\"][\"$\"]\n",
    "                        VOICE = infl[\"voice\"][\"$\"]  \n",
    "                        posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM+\"-\"+TENSE+\"-\"+VOICE\n",
    "                    elif POS == \"pronoun\":\n",
    "                        CASE = infl[\"case\"][\"$\"]\n",
    "                        NUM = infl[\"num\"][\"$\"]\n",
    "                        posentry = POS+\"-\"+CASE+\"-\"+NUM\n",
    "                    elif POS == \"noun\":\n",
    "                        try:\n",
    "                            CASE = infl[\"case\"][\"$\"]\n",
    "                            GEND = infl[\"gend\"][\"$\"]\n",
    "                            NUM = infl[\"num\"][\"$\"]\n",
    "                            posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM \n",
    "                        except KeyError:\n",
    "                            TYPE = infl[\"stemtype\"][\"$\"]\n",
    "                            posentry = POS+\"-\"+TYPE\n",
    "                    elif POS == \"article\":\n",
    "                        CASE = infl[\"case\"][\"$\"]\n",
    "                        GEND = infl[\"gend\"][\"$\"]\n",
    "                        NUM = infl[\"num\"][\"$\"]\n",
    "                        posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                    elif POS == \"adjective\":\n",
    "                        try:\n",
    "                            GEND = infl[\"gend\"][\"$\"]\n",
    "                            if GEND == \"adverbial\":\n",
    "                                posentry = POS+\"-\"+GEND\n",
    "                            else:\n",
    "                                CASE = infl[\"case\"][\"$\"]\n",
    "                                NUM = infl[\"num\"][\"$\"]\n",
    "                                try:\n",
    "                                    COMP = infl[\"comp\"][\"$\"]\n",
    "                                    posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+COMP+\"-\"+NUM\n",
    "                                except KeyError:\n",
    "                                    posentry = POS+\"-\"+CASE+\"-\"+GEND+\"-\"+NUM\n",
    "                        except KeyError:\n",
    "                            CASE = infl[\"case\"][\"$\"]\n",
    "                            NUM = infl[\"num\"][\"$\"]\n",
    "                            try:\n",
    "                                COMP = infl[\"comp\"][\"$\"]\n",
    "                                posentry = POS+\"-\"+CASE+\"-\"+COMP+\"-\"+NUM\n",
    "                            except KeyError:\n",
    "                                posentry = POS+\"-\"+CASE+\"-\"+NUM                            \n",
    "                    else:\n",
    "                        posentry = POS\n",
    "                result[\"Lemma\"] = headword\n",
    "                result[\"Morphology\"] = posentry\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMorpheusLem(\"τινος\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with file\n",
    "\n",
    "Perseids Morpheus can only queried word by word. This takes quite some time... If a queried token was already queried before and therefore is already in the list, then the result is copied from list and Morpheus will not be queried for this token again. This speeds up the query. \n",
    "Also, the lemmatizer writes the results into a file `wordlemma.json`. This json-File is also used to speed up further queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingBar(count,total,size):\n",
    "    percent = float(count)/float(total)*100\n",
    "    sys.stdout.write(\"\\r\" + str(int(count)).rjust(3,'0')+\"/\"+str(int(total)).rjust(3,'0') + ' [' + '='*int(percent/10)*size + ' '*(10-int(percent/10))*size + ']')\n",
    "    \n",
    "word_breaks = RegexpTokenizer(r'\\w+') # whitespace tokenize\n",
    "data_file = open('wordlemma.json')    \n",
    "lemma_data = json.load(data_file)\n",
    "with open('/home/stockhausen/cltk_data/multilingual/text/patristic_text_archive_plaintext/pta0001.pta030.pta-grc1.txt', 'r') as f:\n",
    "    f = f.read().lower()\n",
    "    tokens = word_breaks.tokenize(f)\n",
    "    lemmatized = []\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        count = count+1\n",
    "        loadingBar(count,len(tokens),2)\n",
    "        # check if queried token already in list, if yes, copy from list and don't query Morpheus for speedup\n",
    "        if any(d[\"Word\"] == token for d in lemmatized):\n",
    "            matches = next(d for d in lemmatized if token == d[\"Word\"])\n",
    "            lemmatized.append(matches)\n",
    "        # check if queried token already in wordlemma.json, if yes, copy from wordlemma and don't query Morpheus for speedup    \n",
    "        elif any(d[\"Word\"] == token for d in lemma_data):\n",
    "            matches = next(d for d in lemma_data if token == d[\"Word\"])\n",
    "            lemmatized.append(matches)\n",
    "        else:\n",
    "            result = queryMorpheusLem(token)\n",
    "            lemmatized.append(result)\n",
    "# Delete duplicates from list and write to json file\n",
    "merged_data = lemma_data + lemmatized\n",
    "liste = [i for n, i in enumerate(merged_data) if i not in merged_data[n + 1:]]\n",
    "with open('wordlemma.json', 'w') as fout:\n",
    "    json.dump(liste, fout, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Manual cleanup of wordlemma.json to remove obviously wrong entries (\"errors\") and to choose the most probable entry in case of ambiguous results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View output (Lemmata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmata = [d['Lemma'] for d in lemmatized] # extract all lemmata from list and print\n",
    "print(\"\\n\"+\" \".join(lemmata))\n",
    "# save as file:\n",
    "# with open('/home/stockhausen/cltk_data/user_data/file_lemmatized.txt', 'w') as f:\n",
    "#     f.write(\" \".join(lemmata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with morphology \n",
    "TODO: tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology = [d['Morphology'] for d in lemmatized]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cts-pta-jupyter-venv",
   "language": "python",
   "name": "cts-pta-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
